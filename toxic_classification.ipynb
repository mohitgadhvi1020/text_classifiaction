{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MemFGW7ksHC4"
   },
   "source": [
    "<h2 align=center> Toxic Comments Classification using 1D CNN with Keras</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_XiyvkqfYS0"
   },
   "source": [
    "### Import Packages and Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "PvVbtuzBsHDO",
    "outputId": "6cfea216-0353-4032-a69d-cb5a1f915fbd"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named tensorflow",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-845e1b4976b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named tensorflow"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D\n",
    "#from sklearn.model_selection import train_test_split\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_yPEK8PqgKQt"
   },
   "source": [
    "### Task 2: Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "UkOBp_TDsHDj",
    "outputId": "3780a302-1f23-4115-bf02-f06f10da8067"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-e25651bac530>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-e25651bac530>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    train_df pd.read_csv('train.csv').fillna('')\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv').fillna(' ')\n",
    "train_df.sample(10,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "KLqhFuE2sHDp",
    "outputId": "673cb57d-e7b4-4c31-83e4-c29ecd071200"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "dLEAz9Mx7apX",
    "outputId": "eadfbb06-40f3-4fbd-b300-ef5f7f0d94d4"
   },
   "outputs": [],
   "source": [
    "# View few toxic comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "0hGVtLwo2VlV",
    "outputId": "5ddfdee6-3668-403e-a601-a0de2b786ec9"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "comments = train_df['comment_text'].loc[train_df['toxic']==1].values\n",
    "wordcloud = WordCloud(\n",
    "    width = 640,\n",
    "    height = 640,\n",
    "    background_color = 'black',\n",
    "    stopwords = STOPWORDS).generate(str(comments))\n",
    "fig = plt.figure(\n",
    "    figsize = (12, 8),\n",
    "    facecolor = 'k',\n",
    "    edgecolor = 'k')\n",
    "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "qmfnwRYksHDu",
    "outputId": "11b3e928-ae41-4530-eb22-63f5fd8f809d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "3-pxZLFQw3VR",
    "outputId": "ea865536-9643-455f-899d-a4ae290af3a1"
   },
   "outputs": [],
   "source": [
    "# Plot frequency of toxic comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "8v5D7BG5w_nV",
    "outputId": "0213470a-f0d3-4077-e784-2e3a2ee09039"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IZs1wuFjhxss"
   },
   "source": [
    "### Task 3: Data Prep â€” Tokenize and Pad Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "51i_F9iRsHDV"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-9dc941dd9660>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmax_text_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mx_tokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mx_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mx_tokenized\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mx_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "max_text_length = 400\n",
    "\n",
    "x_tokenizer = text.Tokenizer(max_features)\n",
    "x_tokenizer.fit_on_texts(list(x))\n",
    "x_tokenized  = x_tokenizer.texts_to_sequences(x)\n",
    "x_train_val = sequence.pad_sequences(x_tokenized , maxlen = max_text_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wRuNEC_DsHDy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wki7nrWgiRTp"
   },
   "source": [
    "### Task 4: Prepare Embedding Matrix with Pre-trained GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YTSlrTEOqcW8"
   },
   "outputs": [],
   "source": [
    "#!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "#!unzip -q glove.6B.zip\n",
    "\n",
    "embedding_dim  = 100\n",
    "embedding_index = dict()\n",
    "f = open('glove.6B.100.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:] , dtype = 'float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print(f'Found {len(embeddings_index)} word vectors. ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "08VYEZ8DqwRH"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((max_features , embedding_dim))\n",
    "for word , index in x_tokenizer.word_index.items():\n",
    "    if index > max_features -1:\n",
    "        break\n",
    "    else: \n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ikSokUmeptj"
   },
   "source": [
    "### Task 5: Create the Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHxD6duxf5r5"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features,\n",
    "                   embedding_dim,\n",
    "                   embedding_intializer = tf.keras.intializers.Constant(embedding_matrix),\n",
    "                   trainable=False))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "colab_type": "code",
    "id": "wp8GJRoesHD9",
    "outputId": "f2b2fb77-5248-4d4a-8182-38abb01c0b10"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TwESlTgLsLP2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters =250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv1D(filters,\n",
    "                kernel_size,\n",
    "                padding = 'valid'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(filters,\n",
    "                5,\n",
    "                padding = 'valid',\n",
    "                activation = 'relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(hidden_dims,activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1 , activaion ='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yds9-uJbeygs"
   },
   "source": [
    "### Task 7: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jBAmWQbLsHD4"
   },
   "outputs": [],
   "source": [
    "x_train , x_val , y_train ,y_val train_test_split(x_train_val ,y,\n",
    "                                                 test_size = 0.15 ,random_state =1)\n",
    "\n",
    "%%time\n",
    "batch_size =32\n",
    "epochs =3\n",
    "\n",
    "model.fit(x_train,y_train,batch_size = batch_size,\n",
    "          epochs =3,\n",
    "          validation_data = (x_val ,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "colab_type": "code",
    "id": "ZDQkgmhOsHED",
    "outputId": "bc527adf-9f6d-4c3f-f7a0-91f5f0790a2f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NFFWvo5nfGAP"
   },
   "source": [
    "### Task 8: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "9J54v6q0UEVM",
    "outputId": "7e6fdd2a-6a7f-422a-e1bf-aac493c32b9e"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iNisHnvRsHEK"
   },
   "outputs": [],
   "source": [
    "x_test = test_df['comment_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Su5kx6yjsHEQ"
   },
   "outputs": [],
   "source": [
    "x_test_tokenized = x_tokenizer.texts_to_sequences(x_test)\n",
    "x_testing = sequence.pad_sequences(x_test_tokenized , maxlen = max_text_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4u5at1KRsHEU"
   },
   "outputs": [],
   "source": [
    "y_testing = model.predict(x_testing , verbose =1 ,batch_size =32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "kvgZCuCZsHEZ",
    "outputId": "79ad98e0-52ec-4cdd-dc83-67cf3ca7ee29"
   },
   "outputs": [],
   "source": [
    "y_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "N1dgQKexOyHF",
    "outputId": "eb9d33af-d29f-462b-f761-4db205e3e807"
   },
   "outputs": [],
   "source": [
    "y_testing[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "rYejiiqUG64C",
    "outputId": "60250ec7-365d-4e39-9600-a4bcf72e63e3"
   },
   "outputs": [],
   "source": [
    "test_df['Toxic']= ['not toxic' if x < .5 else 'toxic' for x in y_testing]\n",
    "test_df[['comment_text','Toxic']].head(20) #sample 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "colab_type": "code",
    "id": "m1skya9TiGib",
    "outputId": "5b0909d6-2554-4486-fb79-520ce62d1ac4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Toxic Comments Classification using 1D CNN with Keras.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
